# -Machine-Learning--BNP-Paribas-Insurance-Claims-Management
a kaggle comptition for insurance claims decision 

The goal of our project is to accelerate BNP Paribas Cardif's claims management process. This is a competition in Kaggle. We have trained dataset containing both categorical and numeric variables available when the claims were received by BNP Paribas Cardif. It’s an unbalanced binary classification problem which need us to make claim decision based on those records. We filled in missing values and use some classification algorithms to predicted labels. 

As a global specialist in personal insurance, BNP Paribas Cardif serves 90 million clients in 36 countries across Europe, Asia and Latin America. In a world shaped by the emergence of new uses and lifestyles, everything is going faster and faster. When facing unexpected events, customers expect their insurer to support them as soon as possible. However, claims management may require different levels of check before a claim can be approved and a payment can be made. With the new practices and behaviors generated by the digital economy, this process needs adaptation thanks to data science to meet the new needs and expectations of customers.

We have two main parts in our project. First, the data pre-processing and analysis part, we need to drop some unnecessary features to make data processing easier. For categorical feature, we drop some of them based on analyzing their shapes. And for numerical features, we draw a correlation map to help with the reducing. And we also implemented 6 different methods to fill in missing value, like Mean, ER, KNN, KNN-L, ‘-999’, Mode. Our goal of this part is to have a better dataset which have no missing value, less bias, less high relevance features or add weight on some important features. 
	
The second part is classification. In this part, we have built 6 classifiers as the models, like XGBoost, Naïve Bayes, KNN, Extremely Random Tree, Logistic Regression, SVM, using this model to predict a probability for each claim in the test set. We have used or prepare to use decision tree, logistic regression, Naive Bayes, Adaboost, Xgboost and SVM to train this model. There are more details in 'data description and preprocessing' and 'method description'.

